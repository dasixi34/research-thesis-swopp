\section{まとめと今後の課題}
\label{sec:Conclusion}
本稿では，DPDKのRun-to-Completionモデルを用いたL2分散計算環境を提案した．計算機間の通信にDPDKによるL2通信を用いることによって，TCP/IPによる通信のオーバーヘッドをなくすことやカーネルによるパケットI/Oに比べて高速なパケットI/Oを用いることができる．また，計算機をメッシュネットワークで接続し，Run-to-Completionモデルで処理を実行することによって，Pipelineモデルを用いる場合に比べてコアやCPUのL1キャッシュを有効活用できる．送られてきた32個の値を一定回数足し合わせて送り返すプログラムを用いた事前実験2では，提案手法を用いた場合のスループットはTCP/IPによる通信を用いた場合に比べて最大30倍程度高いことがわかった．また，単回帰分析を行うプログラムを用いた評価では，提案手法を用いた2台での分散学習の実行時間は，1台での集中学習の50\%程度，TCP/IPによる通信を用いた2台での分散学習の83\%程度であることがわかった．

今後の課題としては，使用する計算機の台数を増やして評価を取ること，提案手法のどの部分が性能向上に寄与しているのかを調べるためにRaw Socketを用いてカーネルによるL2通信を実装して評価を取ること，ロジスティック回帰やサポートベクターマシン（Support Vector Machine, SVM）といった複雑な機械学習を実行することなどがある．
