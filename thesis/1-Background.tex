\section{はじめに}
\label{sec:Background}
分散計算環境で実行される処理の中には，与えられたデータを繰り返し用いながら，小さいデータを計算機間でやりとりする処理形態が存在する．例えば，単回帰分析やロジスティック回帰などの機械学習である．これらの処理において，TCP/IPによる制御は計算機内での演算処理時間に比べて，かなり大きなオーバーヘッドとなる．また，カーネルによるパケットI/O処理は，一定時間に受信するパケットの量が増えると，コンテキストスイッチが増加して，割り込み以外の処理が実行できなくなるため，DPDKのパケットI/O処理に比べて低速である．

DPDKにはRun-to-CompletionモデルとPipelineモデルの2つのモデルがある．Run-to-Completionモデルは受信処理，パケット処理，送信処理を一つの論理コアで行い，Pipelineモデルは受信処理，パケット処理，送信処理をそれぞれ別の論理コアで行う．Pipelineモデルはそれぞれの処理が論理コアを専有するため，CPUリソースやL1キャッシュを有効活用できない．

そこで本研究では，DPDKのRun-to-Completionモデルを用いたL2分散計算環境を提案する．計算機間の通信にDPDKによるL2通信を用いることによって，TCP/IPによる通信のオーバーヘッドを低減するとともに，カーネルによるパケットI/O処理に比べて高速なパケットI/O処理を用いることができる．また，Run-to-Completionモデルを採用することによって，Pipelineモデルを用いる場合に比べてCPUリソースやL1キャッシュを有効活用できる．

なお，本研究が提案する分散計算環境には3つの前提を設ける．1つ目の前提はL2通信が可能であるローカルなクラスタ環境で動作することである．2つ目の前提は計算機間でやりとりされるデータのサイズはL2フレームより小さいことである．3つ目の前提は各計算機で実行される処理はイテレーションが多用され，かつ，その実行に必要なデータは小規模であることである．これらの前提は特に機械学習では満たされることが多いと考える．

本稿の構成は以下のとおりである．第\ref{sec:Problem}章で分散計算環境の問題点を述べ，第\ref{sec:DPDK}章でDPDKについて説明する．第\ref{sec:Proposed}章で提案手法について述べ，第\ref{sec:PreExperimentOne}章，第\ref{sec:PreExperimentTwo}章，第\ref{sec:Evaluation}章で提案手法の事前実験と評価を行う．第\ref{sec:RelatedWorks}章で関連研究を述べ，第\ref{sec:Conclusion}章でまとめと今後の課題を述べる．
