\section{はじめに}
\label{sec:Background}
本研究が提案する分散計算環境には3つの前提を設ける．1つ目の前提はL2通信が可能であるローカルなクラスタ環境で動作することである．2つ目の前提は計算機間でやりとりされるデータのサイズはL2フレームの1.5KBより小さいことである．3つ目の前提は各計算機で実行される処理はイテレーションが多いもので，その実行に必要なデータは小規模であることである．これらの前提は特に分散機械学習では満たされることが多いと考える．

TCP/IPによる通信ではルーティング，誤り制御，順序制御といった制御が行われるが，それらは本研究が提案する分散計算環境においてはオーバーヘッドである．また，カーネルによるパケットI/Oには，一定時間に受信するパケットの量が増えると，コンテキストスイッチが増加して，割り込み以外の処理が実行できなくなってしまうといった問題があり，DPDKのパケットI/Oに比べて低速である．

DPDKにはRun-to-CompletionモデルとPipelineモデルの2つのモデルがあるが，Pipelineモデルは受信処理，パケット処理，送信処理をそれぞれ別の論理コアで行うため，コアの使用効率が悪い問題とCPUのL1キャッシュを有効活用できない問題がある．

そこで本研究では，DPDKのRun-to-Completionモデルを用いたL2分散計算環境を提案する．計算機間の通信にDPDKによるL2通信を用いることによって，TCP/IPによる通信のオーバーヘッドをなくすことやカーネルによるパケットI/Oに比べて高速なパケットI/Oを用いることができる．また，計算機をメッシュネットワークで接続し，Run-to-Completionモデルで処理を実行することによって，Pipelineモデルを用いる場合に比べてコアやCPUのL1キャッシュを有効活用できる．

本稿の構成は以下のとおりである．第\ref{sec:Problem}章で分散計算環境の問題点を述べ，第\ref{sec:DPDK}章でDPDKについて説明する．第\ref{sec:RelatedWorks}章で関連研究を述べ，第\ref{sec:Proposed}章で提案手法について述べる．第\ref{sec:PreExperimentOne}章，第\ref{sec:PreExperimentTwo}章，第\ref{sec:Evaluation}章で提案手法の予備実験と評価を行い，第\ref{sec:Conclusion}章でまとめと今後の課題を述べる．
