\begin{abstract}
  本研究が提案する分散計算環境には特に分散機械学習では満たされることが多い3つの前提を設けた．TCP/IPによる通信ではルーティング，誤り制御，順序制御といった制御が行われるが，それらは本研究が提案する分散計算環境の前提を踏まえるとオーバーヘッドである．また，カーネルによるパケットI/OはDPDKのパケットI/Oに比べて低速である．DPDKにはRun-to-CompletionモデルとPipelineモデルの2つのモデルがあるが，Pipelineモデルにはコアの使用効率が悪い問題とCPUのL1キャッシュを有効活用できない問題がある．本研究では，DPDKのRun-to-Completionモデルを用いたL2分散計算環境を提案する．計算機間の通信にDPDKによるL2通信を用いることによって，TCP/IPによる通信のオーバーヘッドをなくすことやカーネルによるパケットI/Oに比べて高速なパケットI/Oを用いることができる．また，計算機をメッシュネットワークで接続し，Run-to-Completionモデルで処理を実行することによって，Pipelineモデルを用いる場合に比べてコアやCPUのL1キャッシュを有効活用できる．送られてきた32個の値を一定回数足し合わせて送り返すプログラムを用いた実験では，提案手法を用いた場合のスループットはTCP/IPによる通信を用いた場合に比べて最大30倍程度高いことがわかった．また，単回帰分析を行うプログラムを用いた評価では，提案手法を用いた2台での分散学習の実行時間は，1台での集中学習の50\%程度，TCP/IPによる通信を用いた2台での分散学習の83\%程度であることがわかった．
\end{abstract}

\begin{jkeyword}
  分散計算環境，DPDK，Run-to-Completion，L2通信，L1キャッシュ
\end{jkeyword}
